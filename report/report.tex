%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University Assignment Title Page 
% LaTeX Template
% Version 1.0 (27/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% WikiBooks (http://en.wikibooks.org/wiki/LaTeX/Title_Creation)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\title{Title page with logo}
%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{color}
\usepackage[explicit]{titlesec}
\usepackage[hyphens,spaces,obeyspaces]{url}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{grffile}
\usepackage{listings}
\usepackage{placeins}
\usepackage[ 
    urldate=long, 
    sorting=none 
]{biblatex} 
\addbibresource{mybib.bib} 

\usepackage{booktabs}
\usepackage{tabularx}

\begin{document}

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE University of St Andrews}\\[1.5cm] % Name of your university/college
\textsc{\Large Computer Graphics}\\[0.5cm] % Major heading such as course name
\textsc{\large CS4102}\\[0.5cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries Interactive 3D Modelling}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------


\Large \emph{Author:}\\
 \textsc{150008022}\\[1cm] % Your name
 
%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[2cm] % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%---------------------------------------------------------------------------------------

\includegraphics[width = 4cm]{images/standrewslogo.png}
 
%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}

\section*{Goal}

The aim of this practical is to understand the key principles behind various techniques
frequently used for the rendering of 3D objects, and to get hands-on experience with their implementation and manipulation.

\pagenumbering{arabic}
\setcounter{page}{1} 

\section{Running the Program}

The project uses \texttt{maven} for lifecycle and dependency management.
\texttt{LWJGL} was used for this project, which provides a way to use \texttt{OpenGL} from Java. 
OpenGL \textit{may} be a cause of compatibility issues when running, but an early and forward compatible profile was used to minimise the risk of this.

\bigskip
\noindent\textbf{Usage} 

\noindent\texttt{mvn clean install} will compile the project, run all tests, and produce an exectuable jar.

\noindent\texttt{cd target} to enter the directory where the jar has been compiled.

\noindent \texttt{java -jar FaceModelling-jar-with-dependencies.jar} to run the program. Pass the \texttt{-h} flag to see options.

\noindent Camera control:
\begin{itemize}
    \item W to move into the screen
    \item S to move out of the screen
    \item A to move left
    \item D to move right
    \item Right click and drag to change orientation
    \item Left click on selection triangle to change weightings (ray tracing not perfect, works best when facing straight on).
\end{itemize}

\section{Implementation}

\subsection{Loading Mesh Data}

A \texttt{FaceLoader} instance initialises by parsing the indices (\texttt{mesh.csv}), and the average face coordinates (\texttt{sh\_000.csv}), vertex weighting (\texttt{sh\_ev.csv}), average face colour (\texttt{tx\_000.csv}), and colour weightings (\texttt{tx\_ev.csv}).
The indices are converted from 1-indexed to 0-indexed when being loaded in.
The \texttt{FaceLoader} instance then loads the deltas for both coordinates and colours for each face, calculating the actual coordinates for each vertex of each face.

The arrays of face data are then passed to the \texttt{MeshLoader} which creates a vertex array object (VAO) for each face, and binds a vertex buffer object (VBO) for the vertices, indices, and colours to them.

The use of indices instead of simply listing all coordinates saves on memory as the one vertex can be used in many triangles, as demonstrated in figure \ref{fig:index_mesh}.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{images/vertex_vs_index}
	\caption{How indices are used when describing meshes.}
	\label{fig:index_mesh}
\end{figure}

\subsection{Depth Testing and Painters Algorithm}

OpenGL does not natively implement painters algorithm for depth testing, and does not expose an API for carrying it out .
Instead, it uses Z-buffers, 
Z-Buffers involve recording the z-index last drawn at each pixel of the window view. 
A pixel with a greater z-index than the current value will be drawn and the z-buffer updated to reflect the new value.
Otherwise the depth test fails and the object will not be drawn at that coordinate.
This functionality is enabled using the \texttt{glEnable(GL11.GL\_DEPTH\_TEST)} call.
An optimisation called early z-testing is often used which is applied earlier on in the rendering pipeline in order to reduce the number of fragments that need to be processed in total.

Painters algorithm and Z-buffers are both viable solutions to the same problem; the former is more computationally expensive while the latter requires more memory.
Z-Buffers are preferred in most cases for modern hardware since memory has become cheaper. 
Painters algorithm also requires additional computation in the case where objects intersect. 
Methods to solve this involve splitting the intersecting shapes and rendering these instead.

A separate renderer was implemented that used painters algorithm.
This renderer was significantly slower both due to the added computation necessary for the painters algorithm, and also due to the fact that the sorting was performed using the CPU rather than the GPU.

The first step involved applying each transformation to the set of coordinates. 
To try improve performance, this task was parallelised using a thread pool.
Then, for each triplet of indices (i.e. each triangle), the maximum Z value was recorded.
Next, maximum z values for each triangle were sorted lowest to highest using a custom \texttt{quicksort} implementation.
The custom implementation was necessary so that every swap performed on the array of maximum z values would also be performed on the indices array, effectively sorting each triangle by maximum z value.
The new indices would then be passed as a VBO for OpenGL, which renders triangles in order of appearance in the indices VBO.

The algorithm does not account for intersecting shapes, which is especially noticeable at the nose of the faces.
Methods for dealing with such intersections include splitting the intersection shapes and painting (or not) the subsections individually.

\subsection{Selection Triangle}

The selection triangle is rendered with the three control faces at each vertex.
A left click on the triangle updates the weighting to be used when producing the interpolated face.
This required carrying out ray casting with respect to the mouse position, and was achieved using the steps described by \cite{screenspace}.
Mapping the left click to a position on the selection triangle involved converting from the 2D screen space coordinates to OpenGLs 3D device coordinate system (Figure \ref{fig:screen_coordinates}).

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{images/screen_coordinates.png}
    \caption{Converting from screen space to OpenGL \cite{lwjglgamedev}.}
	\label{fig:screen_coordinates}
\end{figure}

We then apply the inverse of the transformation matrices we used to convert to screen space to get the coordinates in world space.
A marker is shown on the triangle to represent the current weighting, and the colour of the marker also reflects the current weighting.
The weightings are calculated using a rearrangement of the following system of equations \cite{barycentric}:

$$
P_x = W_{p1}X_{p1} + W_{p2}X_{p2} + W_{p3}X_{p3} 
$$
$$
P_y = W_{p1}Y_{p1} + W_{p2}Y_{p2} + W_{p3}Y_{p3}
$$
$$
1 = W_{p1} + W_{p2} + W_{p3}
$$

If our user clicks outside the bounds of the selection triangle, a negative weighting would be produced, which we can check for before updating the output face.

\subsection{Interpolated Face}

For each vertex of the face, the coordinates can be calculated using the equations for Barycentric coordinates described above.
The output face is rendered at a larger scale than the control faces, just to the right of the selection triangle.

\subsection{Shading}

OpenGL supports both flat and Gouraud shading methods. 
However, the flat shading method only uses the colour from the first vertex of each triangle.
My interpretation of the practical specification was that flat shading should involve using the average colour from each vertex to calculate the colour of every fragment on the face of the triangle.
When accounting for lighting, the face of each triangle would have the same value which could be calculated by taking the cross product of two edges of the triangle (which two affects the direction of the normal), as shown in figure \ref{fig:tri_normal}. 
This would require that each vertex in the mesh that is part of multiple triangles would have a normal value for each triangle it was part of, due to how OpenGL processes VAOs with indices.
This was realised later into development, and would require heavy refactoring to correct. 

Gouraud shading involves calculating a normal per vertex, where this normal is weighted by each triangle that the vertex belongs to.
This weighting can be calculated many ways.
Often logic is included so that hard edges are not rounded.
For this practical, the steps were taken (from \cite{gouraud}):

\begin{enumerate}
\itemsep0em
\item Set all vertex normals to zero
\item For each face, calculate the face normal and add it to the vertex normal for each vertex its touching
\item Normalize all vertex normals
\end{enumerate}

The normal for each point on the surface of each triangle is calculated by again using Barycentric coordinates.

Again, the main issue with implementing the shading fully was the abstraction of OpenGL.
Though the concepts were thoroughly understood, I was not able to implement it.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.4\linewidth]{images/tri-normal.png}
    \caption{Calculating face normal.}
	\label{fig:tri_normal}
\end{figure}

\subsection{Projection}

Both perspective and orthographic projection can be set.

For the perspective projection matrix, the focal length can be set from command line options. 

The transformations from model coordinates to view coordinates involves the multiplication of a series of different transformations:
$$
Transformation = [\textrm{Projection}][\textrm{View}][\textrm{World}]
$$
The world matrix maps the model coordinates (i.e. our face vertices) to how we want it represented in our `world'. 
This includes transformations such as translation, scaling, and rotation.
A scene graph was implemented so that models could be rendered relative to each other.
This is exemplified by the control faces which are positioned relative to the selection triangle.
This involved recursively building a world matrix for each parent.

The view matrix is constructed from the current camera position. 
The camera movement was based on the guide from \cite{lwjglgamedev}.

The perspective projection matrix is calculated using the field of view (hard coded to 60), the aspect ratio (width over height), and the focal length.
Since the camera is used, the focal length described the distance just in front of the camera (hard coded to 0.01f) to the far distance set by the user (default 5f).
The effect of the far distance can be seen if the camera is moved backwards far enough, as the model begin to disappear.

The orthographic projection matrix is calculated by specifying the leftmost coordinate (-1 in OpenGL) rightmost (the aspect ratio was used so that the image was not too stretched by non-square windows), the lowest and highest coordinate, and the near and far distances again.

Since the orthographic view is effectively like having a camera infinitely far away, it behaves differently to the perspective camera.
Zooming in or out does not affect the appearance of the models, therefore the relative sizes of objects are constant regardless of their distance from the viewer.
The widths and heights of objects also remain constant as the user moves in any other direction.

On the other hand, the perspective projection stretches objects as they are approached. 
Zooming in effectively increases the scale of the model.

\section{Conclusion}

Though I was not able to implement everything, the time spent reading to understand the concepts was very beneficial.
Development was drastically hindered by several issues.
For example, when implementing Painters algorithm, a custom implementation of quicksort was used that would cause a stack overflow. 
Time was lost on the assumption that this was due to a logical error, but it was in fact simply due to the large number of elements being sorted, and was corrected by increasing the stack size for the JVM (as mentioned in the usage).
In hindsight the use of OpenGL quickly became more of a curse than a blessing.
It was difficult to determine how much of the functionality was to be written from scratch (for example, it was assumed acceptable to use the \texttt{JOML} matrix functions such as \texttt{setPerspective()} when constructing projection matrices).
For example, when calculating pixel colours, OpenGL uses Gauraud shading by default, and interpolates the colours using Barycentric coordinates for each fragment.
The time spent determining if it was possible to perform these operations myself efficiently would have been better spent including a lighting model which could have been applied to each fragment with knowledge of the vertex normals (these are calculated in the \texttt{Util} class, but not used).

Nevertheless, this project has greatly improved my understanding of computer graphics.

\newpage
\section{Summary of Implementation}
\noindent\textbf{Requirements}
\begin{itemize}
    \itemsep0em
    \item  Render faces using index, coordinate, and colour buffers
    \item  Painters algorithm 
    \item  Click triangle to select weighting between different faces
    \item  Interpolate to create face from control faces with weighting
    \item  Orthographic projection
    \item  Perspective projection
    \item  Adjustable focal length
    \item  Comparison of projection methods
\end{itemize}

\noindent\textbf{Extensions}
\begin{itemize}
\itemsep0em
\item Camera is able to move around 3D world
\item Comparison between painters algorithm and z-buffers 
\item Control faces are also visible during selection
\item Use of OpenGL for optimised rendering
\item Scene graph to render children objects relative to parents
\end{itemize}

\printbibliography

\end{document}
